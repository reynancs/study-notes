{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/reynancs/study-notes/blob/main/regressao_logistica.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "082dff37",
      "metadata": {
        "id": "082dff37"
      },
      "source": [
        "\n",
        "# Aplicação de Regressão Logística para Classificação em Churn\n",
        "\n",
        "**Objetivo:** criar um *notebook de referência* para regressão logística aplicada a problemas de **churn de clientes**, com explicações curtas sobre **o que é**, **como aplicar**, **o que avaliar** e **como interpretar**.  \n",
        "Esse material serve como **apoio** para *case-studies* e *portfolio-projects*.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1ebfc6e9",
      "metadata": {
        "id": "1ebfc6e9"
      },
      "source": [
        "\n",
        "## 1) Introdução (O que é e por que usar)\n",
        "A Regressão Logística é um modelo **linear** que estima a **probabilidade** de um evento (ex.: `churn=1`) a partir de um conjunto de variáveis explicativas.  \n",
        "- **Saída:** probabilidade \\(p(y=1 \\mid x)\\) via função sigmoide.  \n",
        "- **Por que usar em churn:** baseline forte, **interpretável** e rápido de treinar; fornece **coeficientes** úteis para entender fatores de risco.\n",
        "\n",
        "> **Resumo:** use como *baseline*, depois compare com árvores (Decision Tree, Random Forest, XGBoost).\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ffe92ada",
      "metadata": {
        "id": "ffe92ada"
      },
      "source": [
        "\n",
        "## 2) Conceitos / Fundamentos (rápido)\n",
        "- **Função sigmoide:** \\\\(\\sigma(z) = \\frac{1}{1 + e^{-z}}\\\\), com \\\\(z = \\beta_0 + \\beta^T x\\\\).  \n",
        "- **Interpretação:** cada \\\\(\\beta_j\\\\) indica impacto (log-odds). Exponenciando, obtemos **odds ratio**.  \n",
        "- **Custo / Otimização:** normalmente maximização de verossimilhança (ou minimização de log-loss) com **regularização** (\\\\(L2\\\\) por padrão no scikit-learn).  \n",
        "- **Assunções práticas:** relação aproximadamente **linear nos log-odds**; features escaladas ajudam estabilidade numérica; atenção a **multicolinearidade**.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e1168c5d",
      "metadata": {
        "id": "e1168c5d"
      },
      "source": [
        "\n",
        "## 3) Setup (bibliotecas e utilitários)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7bfc60ca",
      "metadata": {
        "id": "7bfc60ca"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Bibliotecas principais\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Visualização\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ML\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    roc_auc_score, confusion_matrix, RocCurveDisplay, PrecisionRecallDisplay\n",
        ")\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Para tratamento de classes desbalanceadas (opcional)\n",
        "try:\n",
        "    from imblearn.over_sampling import SMOTE\n",
        "    IMBLEARN_AVAILABLE = True\n",
        "except Exception:\n",
        "    IMBLEARN_AVAILABLE = False\n",
        "\n",
        "RANDOM_STATE = 42\n",
        "np.random.seed(RANDOM_STATE)\n",
        "print(f\"imblearn disponível? {IMBLEARN_AVAILABLE}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "62b3ea37",
      "metadata": {
        "id": "62b3ea37"
      },
      "source": [
        "\n",
        "## 4) Dados (carregamento e dicionário de variáveis)\n",
        "> Substitua pelo seu dataset. Recomendação: `Telco Customer Churn` (Kaggle) ou o dataset da trilha IBM.  \n",
        "**Como usar:** coloque o CSV em uma pasta `data/` na raiz do projeto e ajuste o caminho abaixo.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5ebefa1",
      "metadata": {
        "id": "a5ebefa1"
      },
      "outputs": [],
      "source": [
        "\n",
        "# === CONFIGURAÇÕES DO USUÁRIO ===\n",
        "DATA_PATH = 'data/telco_churn.csv'  # ajuste para o seu arquivo\n",
        "TARGET_COL = 'Churn'                # ajuste para o nome da sua coluna-alvo (0/1 ou Yes/No)\n",
        "\n",
        "# === TENTATIVA DE CARREGAMENTO ===\n",
        "try:\n",
        "    df = pd.read_csv(DATA_PATH)\n",
        "    print('Dataset carregado:', df.shape)\n",
        "except FileNotFoundError:\n",
        "    print('ATENÇÃO: Arquivo não encontrado. Coloque seu CSV em data/ e ajuste DATA_PATH.')\n",
        "    # Cria um dataset sintético mínimo apenas para ilustrar o pipeline\n",
        "    n = 600\n",
        "    df = pd.DataFrame({\n",
        "        'tenure': np.random.randint(0, 72, size=n),\n",
        "        'MonthlyCharges': np.round(np.random.normal(80, 30, size=n), 2),\n",
        "        'Contract': np.random.choice(['Month-to-month', 'One year', 'Two year'], size=n, p=[0.6,0.25,0.15]),\n",
        "        'SeniorCitizen': np.random.choice([0,1], size=n, p=[0.84, 0.16]),\n",
        "        'TechSupport': np.random.choice(['No', 'Yes'], size=n, p=[0.7, 0.3]),\n",
        "        'Churn': np.random.choice([0,1], size=n, p=[0.73, 0.27])\n",
        "    })\n",
        "    print('Dataset sintético criado:', df.shape)\n",
        "\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ed50b0e3",
      "metadata": {
        "id": "ed50b0e3"
      },
      "source": [
        "\n",
        "### 4.1) Checagens rápidas (EDA leve)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a49e147d",
      "metadata": {
        "id": "a49e147d"
      },
      "outputs": [],
      "source": [
        "\n",
        "display(df.head())\n",
        "print('\\nInfo:')\n",
        "print(df.info())\n",
        "print('\\nDistribuição do alvo:')\n",
        "print(df[TARGET_COL].value_counts(normalize=True).round(3))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "29f49211",
      "metadata": {
        "id": "29f49211"
      },
      "source": [
        "\n",
        "## 5) Preparação dos Dados (pipeline)\n",
        "- Identifique **features numéricas** e **categóricas**.  \n",
        "- Faça **encoding** de categóricas (One-Hot).  \n",
        "- **Escalonamento** ajuda a estabilidade da regressão logística.  \n",
        "- Trate **desbalanceamento** de classes com `class_weight='balanced'` (baseline) ou **SMOTE** (opcional).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0bebf718",
      "metadata": {
        "id": "0bebf718"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Identificar tipos de colunas\n",
        "target = TARGET_COL\n",
        "y = df[target]\n",
        "\n",
        "# Heurística simples para separar numéricas/categóricas\n",
        "numerical_cols = df.drop(columns=[target]).select_dtypes(include=[np.number]).columns.tolist()\n",
        "categorical_cols = df.drop(columns=[target]).select_dtypes(exclude=[np.number]).columns.tolist()\n",
        "\n",
        "print('Numéricas:', numerical_cols)\n",
        "print('Categóricas:', categorical_cols)\n",
        "\n",
        "X = df.drop(columns=[target]).copy()\n",
        "\n",
        "# Pipeline de pré-processamento\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "preprocess = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), numerical_cols),\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Observação: escolha 1 — class_weight='balanced' (mais simples)\n",
        "logreg = LogisticRegression(\n",
        "    max_iter=1000,\n",
        "    class_weight='balanced',\n",
        "    random_state=RANDOM_STATE\n",
        ")\n",
        "\n",
        "pipeline = Pipeline(steps=[('preprocess', preprocess),\n",
        "                          ('model', logreg)])\n",
        "\n",
        "# Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.25, random_state=RANDOM_STATE, stratify=y\n",
        ")\n",
        "X_train.shape, X_test.shape\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f2fa9b75",
      "metadata": {
        "id": "f2fa9b75"
      },
      "source": [
        "\n",
        "> **Alternativa com SMOTE (opcional):** pode melhorar Recall para classe minoritária.  \n",
        "Para usar, habilite o bloco abaixo **apenas se** `imblearn` estiver disponível.  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a13c8666",
      "metadata": {
        "id": "a13c8666"
      },
      "outputs": [],
      "source": [
        "\n",
        "USE_SMOTE = False  # mude para True se quiser aplicar SMOTE\n",
        "\n",
        "if USE_SMOTE and IMBLEARN_AVAILABLE:\n",
        "    from imblearn.pipeline import Pipeline as ImbPipeline\n",
        "    smote = SMOTE(random_state=RANDOM_STATE)\n",
        "    pipeline = ImbPipeline(steps=[('preprocess', preprocess),\n",
        "                                  ('smote', smote),\n",
        "                                  ('model', logreg)])\n",
        "    print('SMOTE habilitado.')\n",
        "else:\n",
        "    print('SMOTE não habilitado.')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "80a18c78",
      "metadata": {
        "id": "80a18c78"
      },
      "source": [
        "\n",
        "## 6) Treinamento\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7753824c",
      "metadata": {
        "id": "7753824c"
      },
      "outputs": [],
      "source": [
        "\n",
        "pipeline.fit(X_train, y_train)\n",
        "print('Treinamento concluído.')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "86cc5085",
      "metadata": {
        "id": "86cc5085"
      },
      "source": [
        "\n",
        "## 7) Avaliação (métricas e curvas)\n",
        "- Em churn, **Recall para a classe \"churn=1\"** geralmente é crítico (não perder quem está para sair).  \n",
        "- Compare também **ROC-AUC** e **F1**.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "035cfd1a",
      "metadata": {
        "id": "035cfd1a"
      },
      "outputs": [],
      "source": [
        "\n",
        "def evaluate(model, X_tr, y_tr, X_te, y_te, positive_label=1):\n",
        "    # Probabilidades (se disponível) e predições\n",
        "    if hasattr(model, 'predict_proba'):\n",
        "        y_proba = model.predict_proba(X_te)[:, 1]\n",
        "    else:\n",
        "        # Se não houver probas, usamos decisão binária como aproximação\n",
        "        y_proba = model.decision_function(X_te)\n",
        "        # Normalização para [0,1] (fallback)\n",
        "        y_proba = (y_proba - y_proba.min()) / (y_proba.max() - y_proba.min() + 1e-9)\n",
        "\n",
        "    y_pred = model.predict(X_te)\n",
        "\n",
        "    metrics = {\n",
        "        'accuracy': accuracy_score(y_te, y_pred),\n",
        "        'precision': precision_score(y_te, y_pred, pos_label=positive_label, zero_division=0),\n",
        "        'recall': recall_score(y_te, y_pred, pos_label=positive_label, zero_division=0),\n",
        "        'f1': f1_score(y_te, y_pred, pos_label=positive_label, zero_division=0),\n",
        "        'roc_auc': roc_auc_score(y_te, y_proba)\n",
        "    }\n",
        "    return metrics, y_pred, y_proba\n",
        "\n",
        "metrics, y_pred, y_proba = evaluate(pipeline, X_train, y_train, X_test, y_test)\n",
        "metrics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0481c778",
      "metadata": {
        "id": "0481c778"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Matriz de confusão\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "cm_df = pd.DataFrame(cm, index=['Real:0','Real:1'], columns=['Pred:0','Pred:1'])\n",
        "cm_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "76bd91dd",
      "metadata": {
        "id": "76bd91dd"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Curva ROC e PR\n",
        "fig, ax = plt.subplots(figsize=(6,4))\n",
        "RocCurveDisplay.from_predictions(y_test, y_proba, ax=ax)\n",
        "plt.title('ROC Curve - Logistic Regression')\n",
        "plt.show()\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(6,4))\n",
        "PrecisionRecallDisplay.from_predictions(y_test, y_proba, ax=ax)\n",
        "plt.title('Precision-Recall Curve - Logistic Regression')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e6e3d25e",
      "metadata": {
        "id": "e6e3d25e"
      },
      "source": [
        "\n",
        "## 8) Interpretação: Coeficientes e Odds Ratios\n",
        "> Importante: após o `ColumnTransformer`, as features são expandidas (one-hot). Precisamos recuperar seus **nomes transformados** para interpretar os coeficientes.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a0bd328",
      "metadata": {
        "id": "9a0bd328"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Recuperar nomes das features após o OneHotEncoder\n",
        "ohe = pipeline.named_steps['preprocess'].named_transformers_['cat']\n",
        "num_features = numerical_cols\n",
        "cat_features = list(ohe.get_feature_names_out(categorical_cols)) if len(categorical_cols) > 0 else []\n",
        "all_features = num_features + cat_features\n",
        "\n",
        "# Coeficientes do modelo\n",
        "clf = pipeline.named_steps['model']\n",
        "coefs = clf.coef_.ravel()\n",
        "\n",
        "coef_df = pd.DataFrame({\n",
        "    'feature': all_features,\n",
        "    'coef': coefs,\n",
        "    'odds_ratio': np.exp(coefs)\n",
        "}).sort_values(by='odds_ratio', ascending=False)\n",
        "\n",
        "coef_df.head(15)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c2b34333",
      "metadata": {
        "id": "c2b34333"
      },
      "source": [
        "\n",
        "> **Leitura rápida:**  \n",
        "- `odds_ratio > 1`: aumento nos *odds* de churn quando a feature cresce (ou quando a categoria está presente).  \n",
        "- `odds_ratio < 1`: redução nos *odds* de churn.  \n",
        "- **Atenção:** interpretação válida **mantendo as demais variáveis constantes**.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa1f2143",
      "metadata": {
        "id": "aa1f2143"
      },
      "source": [
        "\n",
        "## 9) (Opcional) Ajuste de limiar de decisão\n",
        "Em problemas desbalanceados, alterar o **threshold** pode melhorar Recall para a classe positiva (churn).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb6ea90c",
      "metadata": {
        "id": "eb6ea90c"
      },
      "outputs": [],
      "source": [
        "\n",
        "thresholds = np.linspace(0.1, 0.9, 9)\n",
        "rows = []\n",
        "for th in thresholds:\n",
        "    y_hat = (y_proba >= th).astype(int)\n",
        "    rows.append({\n",
        "        'threshold': th,\n",
        "        'precision': precision_score(y_test, y_hat, zero_division=0),\n",
        "        'recall': recall_score(y_test, y_hat, zero_division=0),\n",
        "        'f1': f1_score(y_test, y_hat, zero_division=0)\n",
        "    })\n",
        "pd.DataFrame(rows)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eb9e180d",
      "metadata": {
        "id": "eb9e180d"
      },
      "source": [
        "\n",
        "## 10) (Gancho) Comparação com outros modelos\n",
        "Para transformar este *reference notebook* em **case-study**, adicione:\n",
        "- Decision Tree (baseline interpretável)\n",
        "- Random Forest e/ou XGBoost (modelos avançados)\n",
        "\n",
        "No fim, crie uma **tabela comparativa** com as mesmas métricas.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2114e6db",
      "metadata": {
        "id": "2114e6db"
      },
      "source": [
        "\n",
        "## 11) Resumo (para colar no seu repositório de *study notes*)\n",
        "- **O que é:** modelo linear probabilístico (log-odds).  \n",
        "- **Como aplicar:** pipeline (preprocess → train → evaluate).  \n",
        "- **O que avaliar:** Recall, F1, ROC-AUC, matriz de confusão.  \n",
        "- **Destaques:** interpretável, rápido; ótimo como baseline em churn; atenção a escala e desbalanceamento.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}